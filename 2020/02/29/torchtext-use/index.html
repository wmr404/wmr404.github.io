<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Torchtext使用教程, WANGJI&#39;s BLOG">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Torchtext使用教程 | WANGJI&#39;s BLOG</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="WANGJI's BLOG" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">WANGJI's BLOG</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">WANGJI's BLOG</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
    </ul>
</div>

        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/images/torchtext_use/torchtext.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Torchtext使用教程</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/torchtext/">
                                <span class="chip bg-color">torchtext</span>
                            </a>
                        
                            <a href="/tags/python/">
                                <span class="chip bg-color">python</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/NLP/" class="post-category">
                                NLP
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-02-29
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2020-02-29
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    2.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    12 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Torchtext使用教程"><a href="#Torchtext使用教程" class="headerlink" title="Torchtext使用教程"></a>Torchtext使用教程</h1><h2 id="主要内容："><a href="#主要内容：" class="headerlink" title="主要内容："></a>主要内容：</h2><ul>
<li>如何使用torchtext建立语料库</li>
<li>如何使用torchtext将词转下标，下标转词，词转词向量</li>
<li>如何建立相应的迭代器</li>
</ul>
<h2 id="torchtext预处理流程："><a href="#torchtext预处理流程：" class="headerlink" title="torchtext预处理流程："></a>torchtext预处理流程：</h2><ol>
<li>定义Field：声明如何处理数据</li>
<li>定义Dataset：得到数据集，此时数据集里每一个样本是一个 经过 <strong>Field声明的预处理</strong> 预处理后的 wordlist</li>
<li>建立vocab：在这一步建立词汇表，词向量(word embeddings)</li>
<li>构造迭代器：构造迭代器，用来分批次训练模型</li>
</ol>
<h1 id="1-下载数据："><a href="#1-下载数据：" class="headerlink" title="1. 下载数据："></a>1. 下载数据：</h1><p><a href="https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only/data" target="_blank" rel="noopener">kaggle：Movie Review Sentiment Analysis (Kernels Only)</a><br>train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.</p>
<p>test.tsv contains just phrases. You must assign a sentiment label to each phrase.</p>
<p>The sentiment labels are:<br>0 - negative<br>1 - somewhat negative<br>2 - neutral<br>3 - somewhat positive<br>4 - positive</p>
<p>下载得到：train.tsv和test.tsv</p>
<h2 id="读取文件，查看文件"><a href="#读取文件，查看文件" class="headerlink" title="读取文件，查看文件"></a>读取文件，查看文件</h2><pre><code>import pandas as pd
data = pd.read_csv('train.tsv', sep='\t')
test = pd.read_csv('test.tsv', sep='\t')</code></pre><h3 id="train-tsv"><a href="#train-tsv" class="headerlink" title="train.tsv"></a>train.tsv</h3><pre><code>data[:5]</code></pre><p><img src="https://img-blog.csdnimg.cn/20190619123238831.png" alt=""></p>
<h3 id="test-tsv"><a href="#test-tsv" class="headerlink" title="test.tsv"></a>test.tsv</h3><pre><code>test[:5]</code></pre><p><img src="https://img-blog.csdnimg.cn/20190619123248113.png" alt=""></p>
<h1 id="2-划分验证集"><a href="#2-划分验证集" class="headerlink" title="2. 划分验证集"></a>2. 划分验证集</h1><pre><code>from sklearn.model_selection import train_test_split
# create train and validation set 

train, val = train_test_split(data, test_size=0.2)
train.to_csv("train.csv", index=False)
val.to_csv("val.csv", index=False)</code></pre><h1 id="3-定义Field"><a href="#3-定义Field" class="headerlink" title="3. 定义Field"></a>3. 定义Field</h1><p>首先导入需要的包和定义pytorch张量使用的DEVICE</p>
<pre><code>import spacy
import torch
from torchtext import data, datasets
from torchtext.vocab import Vectors
from torch.nn import init

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")</code></pre><p>Torchtext采用了一种声明式的方法来加载数据：你来告诉Torchtext你希望的数据是什么样子的，剩下的由torchtext来处理。<br>实现这种声明的是Field，Field确定了一种你想要怎么去处理数据。<br>data.Field(…)</p>
<p>Field的参数如下：</p>
<ul>
<li>sequential: Whether the datatype represents sequential data. If False, no tokenization is applied. Default: True.</li>
<li>use_vocab: Whether to use a Vocab object. If False, the data in this field should already be numerical. Default: True.</li>
<li>init_token: A token that will be prepended to every example using this field, or None for no initial token. Default: None.</li>
<li>eos_token: A token that will be appended to every example using this field, or None for no end-of-sentence token. Default: None.</li>
<li>fix_length: A fixed length that all examples using this field will be padded to, or None for flexible sequence lengths. Default: None.</li>
<li>dtype: The torch.dtype class that represents a batch of examples of this kind of data. Default: torch.long.</li>
<li>preprocessing: The Pipeline that will be applied to examples using this field after tokenizing but before numericalizing. Many Datasets replace this attribute with a custom preprocessor. Default: None.</li>
<li>postprocessing: A Pipeline that will be applied to examples using this field after numericalizing but before the numbers are turned into a Tensor. The pipeline function takes the batch as a list, and the field’s Vocab. Default: None.</li>
<li>lower: Whether to lowercase the text in this field. Default: False.</li>
<li>tokenize: The function used to tokenize strings using this field into sequential examples. If “spacy”, the SpaCy tokenizer is used. If a non-serializable function is passed as an argument, the field will not be able to be serialized. Default: string.split.</li>
<li>tokenizer_language: The language of the tokenizer to be constructed. Various languages currently supported only in SpaCy.</li>
<li>include_lengths: Whether to return a tuple of a padded minibatch and a list containing the lengths of each examples, or just a padded minibatch. Default: False.</li>
<li>batch_first: Whether to produce tensors with the batch dimension first. Default: False.</li>
<li>pad_token: The string token used as padding. Default: “<pad>“.</pad></li>
<li>unk_token: The string token used to represent OOV words. Default: “<unk>“.</unk></li>
<li>pad_first: Do the padding of the sequence at the beginning. Default: False.</li>
<li>truncate_first: Do the truncating of the sequence at the beginning. Default: False</li>
<li>stop_words: Tokens to discard during the preprocessing step. Default: None</li>
<li>is_target: Whether this field is a target variable. Affects iteration over batches. Default: False</li>
</ul>
<p><strong>例：</strong></p>
<pre><code>spacy_en = spacy.load('en')

def tokenizer(text): # create a tokenizer function
    """
    定义分词操作
    """
    return [tok.text for tok in spacy_en.tokenizer(text)]

"""
field在默认的情况下都期望一个输入是一组单词的序列，并且将单词映射成整数。
这个映射被称为vocab。如果一个field已经被数字化了并且不需要被序列化，
可以将参数设置为use_vocab=False以及sequential=False。
"""
LABEL = data.Field(sequential=False, use_vocab=False)

TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True)
</code></pre><h1 id="4-定义Dataset"><a href="#4-定义Dataset" class="headerlink" title="4. 定义Dataset"></a>4. 定义Dataset</h1><p>The fields知道当给定原始数据的时候要做什么。现在，我们需要告诉fields它需要处理什么样的数据。这个功能利用Datasets来实现。</p>
<p>Torchtext有大量内置的<a href="https://torchtext.readthedocs.io/en/latest/datasets.html" target="_blank" rel="noopener">Datasets</a>去处理各种数据格式。</p>
<p><strong>TabularDataset官网介绍: Defines a Dataset of columns stored in CSV, TSV, or JSON format.</strong></p>
<p>对于csv/tsv类型的文件，TabularDataset很容易进行处理，故我们选它来生成Dataset</p>
<pre><code>"""
我们不需要 'PhraseId' 和 'SentenceId'这两列, 所以我们给他们的field传递 None
如果你的数据有列名，如我们这里的'Phrase','Sentiment',...
设置skip_header=True,不然它会把列名也当一个数据处理
"""
train,val = data.TabularDataset.splits(
        path='.', train='train.csv',validation='val.csv', format='csv',skip_header=True,
        fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT), ('Sentiment', LABEL)])

test = data.TabularDataset('test.tsv', format='tsv',skip_header=True,
        fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT)])</code></pre><p><strong>注意：传入的(name, field)必须与列的顺序相同。</strong></p>
<p>查看生成的dataset：</p>
<pre><code>print(train[5])
print(train[5].__dict__.keys())
print(train[5].Phrase,train[0].Sentiment)</code></pre><p>输出：<br><img src="https://img-blog.csdnimg.cn/201906191233142.png" alt=""></p>
<h1 id="5-建立vocab"><a href="#5-建立vocab" class="headerlink" title="5. 建立vocab"></a>5. 建立vocab</h1><p>我们可以看到第6行的输入，它是一个Example对象。Example对象绑定了一行中的所有属性，可以看到，句子已经被分词了，但是没有转化为数字。</p>
<p>这是因为我们还没有建立vocab，我们将在下一步建立vocab。</p>
<p>Torchtext可以将词转化为数字，但是它需要被告知需要被处理的全部范围的词。我们可以用下面这行代码：</p>
<pre><code>TEXT.build_vocab(train, vectors='glove.6B.100d')#, max_size=30000)
# 当 corpus 中有的 token 在 vectors 中不存在时 的初始化方式.
TEXT.vocab.vectors.unk_init = init.xavier_uniform</code></pre><p>这行代码使得 Torchtext遍历<strong>训练集</strong>中的绑定TEXT field的数据，将单词注册到vocabulary，并自动构建embedding矩阵。</p>
<p><strong>‘glove.6B.100d’ 为torchtext支持的词向量名字，第一次使用是会自动下载并保存在当前目录的 .vector_cache里面。</strong></p>
<p><strong>torchtext支持的词向量</strong></p>
<ul>
<li>charngram.100d</li>
<li>fasttext.en.300d</li>
<li>fasttext.simple.300d</li>
<li>glove.42B.300d</li>
<li>glove.840B.300d</li>
<li>glove.twitter.27B.25d</li>
<li>glove.twitter.27B.50d</li>
<li>glove.twitter.27B.100d</li>
<li>glove.twitter.27B.200d</li>
<li>glove.6B.50d</li>
<li>glove.6B.100d</li>
<li>glove.6B.200d</li>
<li>glove.6B.300d</li>
</ul>
<p><strong>例：</strong></p>
<p>如果打算使用fasttext.en.300d词向量，只需把上面的代码里的vector=’…’里面的词向量名字换一下即可，具体如下：</p>
<pre><code>TEXT.build_vocab(train, vectors='fasttext.en.300d')</code></pre><p>到这一步，我们已经可以把<strong>词转为数字，数字转为词，词转为词向量</strong>了</p>
<pre><code>print(TEXT.vocab.itos[1510])
print(TEXT.vocab.stoi['bore'])
# 词向量矩阵: TEXT.vocab.vectors
print(TEXT.vocab.vectors.shape)
word_vec = TEXT.vocab.vectors[TEXT.vocab.stoi['bore']]
print(word_vec.shape)
print(word_vec)</code></pre><p>输出：<br><img src="https://img-blog.csdnimg.cn/20190619123330249.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0pXb3N3aW4=,size_16,color_FFFFFF,t_70" alt=""></p>
<h1 id="6-构造迭代器"><a href="#6-构造迭代器" class="headerlink" title="6. 构造迭代器"></a>6. 构造迭代器</h1><p>我们日常使用pytorch训练网络时，每次训练都是输入一个batch，那么，我们怎么把前面得到的dataset转为迭代器，然后遍历迭代器获取batch输入呢？下面将介绍torchtext时怎么实现这一功能的。</p>
<p>和Dataset一样，torchtext有大量内置的迭代器，我们这里选择的是BucketIterator，官网对它的介绍如下：</p>
<ul>
<li>Defines an iterator that batches examples of similar lengths together.</li>
<li>Minimizes amount of padding needed while producing freshly shuffled batches for each new epoch. </li>
</ul>
<pre><code>train_iter = data.BucketIterator(train, batch_size=128, sort_key=lambda x: len(x.Phrase), 
                                 shuffle=True,device=DEVICE)

val_iter = data.BucketIterator(val, batch_size=128, sort_key=lambda x: len(x.Phrase), 
                                 shuffle=True,device=DEVICE)

# 在 test_iter , sort一定要设置成 False, 要不然会被 torchtext 搞乱样本顺序
test_iter = data.Iterator(dataset=test, batch_size=128, train=False,
                          sort=False, device=DEVICE)</code></pre><h2 id="迭代器使用"><a href="#迭代器使用" class="headerlink" title="迭代器使用"></a>迭代器使用</h2><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><pre><code>batch = next(iter(train_iter))
data = batch.Phrase
label = batch.Sentiment
print(batch.Phrase.shape)
print(batch.Phrase)</code></pre><p>输出结果：<br><img src="https://img-blog.csdnimg.cn/20190619123347960.png" alt=""><br>可以发现，它输出的是word index，后面的128是batch size</p>
<h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><pre><code>for batch in train_iter:
    data = batch.Phrase
    label = batch.Sentiment</code></pre><h1 id="7-完整代码"><a href="#7-完整代码" class="headerlink" title="7. 完整代码"></a>7. 完整代码</h1><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> spacy
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torchtext <span class="token keyword">import</span> data<span class="token punctuation">,</span> datasets
<span class="token keyword">from</span> torchtext<span class="token punctuation">.</span>vocab <span class="token keyword">import</span> Vectors
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> init
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

DEVICE <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'train.tsv'</span><span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
test <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'test.tsv'</span><span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># create train and validation set </span>
train<span class="token punctuation">,</span> val <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>data<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
train<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"train.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
val<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"val.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

spacy_en <span class="token operator">=</span> spacy<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'en'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">tokenizer</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># create a tokenizer function</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>tok<span class="token punctuation">.</span>text <span class="token keyword">for</span> tok <span class="token keyword">in</span> spacy_en<span class="token punctuation">.</span>tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># Field</span>
TEXT <span class="token operator">=</span> data<span class="token punctuation">.</span>Field<span class="token punctuation">(</span>sequential<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> tokenize<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> lower<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
LABEL <span class="token operator">=</span> data<span class="token punctuation">.</span>Field<span class="token punctuation">(</span>sequential<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> use_vocab<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Dataset</span>
train<span class="token punctuation">,</span>val <span class="token operator">=</span> data<span class="token punctuation">.</span>TabularDataset<span class="token punctuation">.</span>splits<span class="token punctuation">(</span>
        path<span class="token operator">=</span><span class="token string">'.'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token string">'train.csv'</span><span class="token punctuation">,</span>validation<span class="token operator">=</span><span class="token string">'val.csv'</span><span class="token punctuation">,</span> format<span class="token operator">=</span><span class="token string">'csv'</span><span class="token punctuation">,</span>skip_header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        fields<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'PhraseId'</span><span class="token punctuation">,</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">'SentenceId'</span><span class="token punctuation">,</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">'Phrase'</span><span class="token punctuation">,</span> TEXT<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'Sentiment'</span><span class="token punctuation">,</span> LABEL<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

test <span class="token operator">=</span> data<span class="token punctuation">.</span>TabularDataset<span class="token punctuation">(</span><span class="token string">'test.tsv'</span><span class="token punctuation">,</span> format<span class="token operator">=</span><span class="token string">'tsv'</span><span class="token punctuation">,</span>skip_header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        fields<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'PhraseId'</span><span class="token punctuation">,</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">'SentenceId'</span><span class="token punctuation">,</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">'Phrase'</span><span class="token punctuation">,</span> TEXT<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># build vocab</span>
TEXT<span class="token punctuation">.</span>build_vocab<span class="token punctuation">(</span>train<span class="token punctuation">,</span> vectors<span class="token operator">=</span><span class="token string">'glove.6B.100d'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#, max_size=30000)</span>
TEXT<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>vectors<span class="token punctuation">.</span>unk_init <span class="token operator">=</span> init<span class="token punctuation">.</span>xavier_uniform

<span class="token comment" spellcheck="true"># Iterator</span>
train_iter <span class="token operator">=</span> data<span class="token punctuation">.</span>BucketIterator<span class="token punctuation">(</span>train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> sort_key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> len<span class="token punctuation">(</span>x<span class="token punctuation">.</span>Phrase<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                                 shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>device<span class="token operator">=</span>DEVICE<span class="token punctuation">)</span>

val_iter <span class="token operator">=</span> data<span class="token punctuation">.</span>BucketIterator<span class="token punctuation">(</span>val<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> sort_key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> len<span class="token punctuation">(</span>x<span class="token punctuation">.</span>Phrase<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                                 shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>device<span class="token operator">=</span>DEVICE<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 在 test_iter , sort一定要设置成 False, 要不然会被 torchtext 搞乱样本顺序</span>
test_iter <span class="token operator">=</span> data<span class="token punctuation">.</span>Iterator<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                          sort<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> device<span class="token operator">=</span>DEVICE<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
由于目的是学习torchtext的使用，所以只定义了一个简单模型
"""</span>
len_vocab <span class="token operator">=</span> len<span class="token punctuation">(</span>TEXT<span class="token punctuation">.</span>vocab<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Enet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>Enet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>len_vocab<span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#,bidirectional=True)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size<span class="token punctuation">,</span>seq_num <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        vec <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out<span class="token punctuation">,</span> <span class="token punctuation">(</span>hn<span class="token punctuation">,</span> cn<span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm<span class="token punctuation">(</span>vec<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>out<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> out


model <span class="token operator">=</span> Enet<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
将前面生成的词向量矩阵拷贝到模型的embedding层
这样就自动的可以将输入的word index转为词向量
"""</span>
model<span class="token punctuation">.</span>embedding<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>copy_<span class="token punctuation">(</span>TEXT<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>vectors<span class="token punctuation">)</span>   
model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 训练</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#,lr=0.000001)</span>

n_epoch <span class="token operator">=</span> <span class="token number">20</span>

best_val_acc <span class="token operator">=</span> <span class="token number">0</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>n_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> batch <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> batch<span class="token punctuation">.</span>Phrase
        target <span class="token operator">=</span> batch<span class="token punctuation">.</span>Sentiment
        target <span class="token operator">=</span> torch<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span>torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token operator">=</span>target<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">)</span>
        target <span class="token operator">=</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
        data <span class="token operator">=</span> data<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> <span class="token operator">-</span>target<span class="token operator">*</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>target<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>out<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>

        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span>batch_idx<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span><span class="token number">200</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            _<span class="token punctuation">,</span>y_pre <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>out<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            acc <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y_pre <span class="token operator">==</span> batch<span class="token punctuation">.</span>Sentiment<span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch: %d \t batch_idx : %d \t loss: %.4f \t train acc: %.4f'</span>
                  <span class="token operator">%</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>batch_idx<span class="token punctuation">,</span>loss<span class="token punctuation">,</span>acc<span class="token punctuation">)</span><span class="token punctuation">)</span>

    val_accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> batch <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>val_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> batch<span class="token punctuation">.</span>Phrase
        target <span class="token operator">=</span> batch<span class="token punctuation">.</span>Sentiment
        target <span class="token operator">=</span> torch<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span>torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token operator">=</span>target<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">)</span>
        target <span class="token operator">=</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
        data <span class="token operator">=</span> data<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

        _<span class="token punctuation">,</span>y_pre <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>out<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        acc <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y_pre <span class="token operator">==</span> batch<span class="token punctuation">.</span>Sentiment<span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        val_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">)</span>

    acc <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>val_accs<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> acc <span class="token operator">></span> best_val_acc<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'val acc : %.4f > %.4f saving model'</span><span class="token operator">%</span><span class="token punctuation">(</span>acc<span class="token punctuation">,</span>best_val_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'params.pkl'</span><span class="token punctuation">)</span>
        best_val_acc <span class="token operator">=</span> acc
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'val acc: %.4f'</span><span class="token operator">%</span><span class="token punctuation">(</span>acc<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<h1 id="8-参考"><a href="#8-参考" class="headerlink" title="8. 参考"></a>8. 参考</h1><ul>
<li><a href="https://zhuanlan.zhihu.com/p/65833208" target="_blank" rel="noopener">pytorch学习笔记—Torchtext</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/34722385" target="_blank" rel="noopener">使用 torchtext 做 Toxic Comment Classification 比赛的数据预处理</a></li>
<li><a href="https://towardsdatascience.com/how-to-use-torchtext-for-neural-machine-translation-plus-hack-to-make-it-5x-faster-77f3884d95" target="_blank" rel="noopener">How to use TorchText for neural machine translation, plus hack to make it 5x faster</a></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://wangjiosw.github.io" rel="external nofollow noreferrer">wangji</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://wangjiosw.github.io/2020/02/29/torchtext-use/">https://wangjiosw.github.io/2020/02/29/torchtext-use/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://wangjiosw.github.io" target="_blank">wangji</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/torchtext/">
                                    <span class="chip bg-color">torchtext</span>
                                </a>
                            
                                <a href="/tags/python/">
                                    <span class="chip bg-color">python</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'f1dea0db9a849adbc56a',
        clientSecret: '32b450bd795d5f65e217c2bf16d0adef430b5641',
        repo: 'blogtalk',
        owner: 'wmr404',
        admin: "wmr404",
        id: '2020-02-29T21-25-00',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2020/02/29/vmware/">
                    <div class="card-image">
                        
                        <img src="/images/vmware/vmware.jpeg" class="responsive-img" alt="Mac OS VMware Fusion Centos6.5虚拟机网络设置">
                        
                        <span class="card-title">Mac OS VMware Fusion Centos6.5虚拟机网络设置</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            大数据环境：Mac OS VMware Fusion Centos6.5虚拟机网络设置
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-02-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="post-category">
                                    大数据
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/vmware/">
                        <span class="chip bg-color">vmware</span>
                    </a>
                    
                    <a href="/tags/macos/">
                        <span class="chip bg-color">macos</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/02/29/hello-world/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/12.jpg" class="responsive-img" alt="Hello World">
                        
                        <span class="card-title">Hello World</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hex
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-02-29
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            wangji
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="https://wangjiosw.github.io" target="_blank">wangji</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">2.9k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/wmr404" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:flesymebot@outlook.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-143765688-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', 'UA-143765688-1');
</script>


    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    
    
    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
